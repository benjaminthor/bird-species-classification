{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment1 - Bird Species - Classification - Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SubsetRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as transform\n",
    "from torchvision.io import read_image\n",
    "from torchsummary import summary\n",
    "#from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# data_dir = '/Users/Public/Documents/'\n",
    "data_dir = '/workspace'\n",
    "train_dir = os.path.join(data_dir,'train')\n",
    "valid_dir = os.path.join(data_dir,'valid')\n",
    "test_dir = os.path.join(data_dir,'test')\n",
    "mf = data_dir + \"/birds.csv\"\n",
    "df = pd.read_csv(data_dir + \"/birds.csv\")\n",
    "input_shape = (224, 224, 3)   # (img_width, img_height, n_chanel)\n",
    "\n",
    "seed = 2020\n",
    "torch.manual_seed(seed)\n",
    "if(torch.has_cuda) :\n",
    "    device = torch.device('cuda')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(data_loader):\n",
    "# obtain one batch of training images\n",
    "    dataiter = iter(data_loader)\n",
    "    images, labels = next(dataiter)\n",
    "    images = images.numpy() # convert images to numpy for display\n",
    "\n",
    "    # plot the images in the batch, along with the corresponding labels\n",
    "    fig = plt.figure(figsize=(15,5))\n",
    "    for idx in np.arange(10):\n",
    "        ax = fig.add_subplot(2, 5, idx+1, xticks=[], yticks=[])\n",
    "        plt.imshow(np.transpose(images[idx], (1, 2, 0)))\n",
    "        ax.set_title(labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(data, batch_s, sampler, workrs=0):\n",
    "    return DataLoader(\n",
    "        dataset = data, \n",
    "        batch_size = batch_s,\n",
    "        sampler = sampler,\n",
    "        num_workers = workrs    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    fig, ax = plt.subplots(1,2,figsize=(12,4))\n",
    "    ax[0].plot(history['train_acc'])\n",
    "    ax[0].plot(history['valid_acc'])\n",
    "    ax[0].set_title('Model accuracy')\n",
    "    ax[0].set_ylabel('Accuracy')\n",
    "    ax[0].set_xlabel('10-Epochs for 1-Fold')\n",
    "    ax[0].legend(['Train', 'Valid'], loc='upper left')\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    ax[1].plot(history['train_loss'])\n",
    "    ax[1].plot(history['valid_loss'])\n",
    "    ax[1].set_title('Model loss')\n",
    "    ax[1].set_ylabel('Loss')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].legend(['Train', 'Valid'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function responsible for reading the images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images_from_directory(directory, input_shape) :\n",
    "    from PIL import Image\n",
    "    # Database reading\n",
    "    classes = glob.glob(directory +'/train/*') ## Array containing the directory of each class\n",
    "    # print(classes)\n",
    "    X = []\n",
    "    y = []\n",
    "    labels = []\n",
    "    for i in range(len(classes)): ## For each directory, reads all images\n",
    "        files = glob.glob (classes[i] + \"/*\") \n",
    "        for myFile in files: \n",
    "            im = Image.open(myFile)\n",
    "            im = np.array(im)\n",
    "            X.append(im)\n",
    "            y.append(classes[i] .split('/')[-1])  ## Array containing class labels\n",
    "            labels.append(myFile.split('/')[-1].split('.')[0])\n",
    "  \n",
    "    del directory, classes, i, files, myFile, im ## Remove variables that will no longer be used\n",
    "    \n",
    "    return np.asarray(X), np.asarray(y), np.asarray(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, m, z = read_images_from_directory(data_dir, 4) ## n = array by RGB for all images, m = arrat class labels, z = array for pathdirectory to images\n",
    "#run a lot of time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a path to data files and describing the files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 70626\n",
      "Test set size: 2250\n",
      "Validation set size: 2250\n",
      "Total number of classes: 450\n"
     ]
    }
   ],
   "source": [
    "test_images = glob.glob(data_dir+'/images to test/*')\n",
    "train = glob.glob(train_dir+'/*/*')\n",
    "test = glob.glob(test_dir+'/*/*')\n",
    "valid  = glob.glob(valid_dir+'/*/*')\n",
    "classes = glob.glob(train_dir+'/*')\n",
    "print(f'Train set size: {len(train)}\\nTest set size: {len(test)}\\nValidation set size: {len(valid)}\\nTotal number of classes: {len(classes)}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data transforms & dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation is a good practice for the train set, after we saw in part1 that there is some classes that have small amount of training samples\n",
    "# Here, we can do some transformation. we start with part of them:\n",
    "# crop images to 224x224, random rotation of 20+- degrees for training set \n",
    "\n",
    "data_transforms_train = transforms.Compose([\n",
    "        # transforms.ToPILImage(), ## For it can be display as image to see transformation\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.RandomRotation(20), \n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "data_transforms_other = transforms.Compose([\n",
    "        # transforms.ToPILImage(), \n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to check\n",
    "\n",
    "class_dict = {}\n",
    "classes_1 = os.listdir(data_dir + '/train')\n",
    "#Creating a dictionary of the classes and their corresponding img count\n",
    "for class_name in classes_1:\n",
    "    try:\n",
    "        temp_path = os.path.join(train_dir, class_name)\n",
    "        class_dict[class_name] = len(os.listdir(temp_path))\n",
    "    except:\n",
    "        pass\n",
    "#Creating a dataframe of the classes and their corresponding img count\n",
    "classes = pd.DataFrame(class_dict.items(), columns = ['class_name', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of all images \n",
    "train_imgs = []\n",
    "valid_imgs = []\n",
    "test_imgs = []\n",
    "\n",
    "for _class in classes_1:\n",
    "    for img in os.listdir(data_dir + \"/train/\" + _class):\n",
    "        train_imgs.append(data_dir +\"/train/\"+ _class + \"/\" + img)\n",
    "    \n",
    "    for img in os.listdir(data_dir + \"/valid/\" + _class):\n",
    "        valid_imgs.append(data_dir + \"/valid/\" + _class + \"/\" + img)\n",
    "        \n",
    "    for img in os.listdir(data_dir  + \"/test/\" + _class):\n",
    "        test_imgs.append(data_dir + \"/test/\" + _class + \"/\" + img)\n",
    "\n",
    "# Make dictonary\n",
    "# class_to_int = {classes[i] : i for i in range(len(classes_1))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Birds_dataset(Dataset):\n",
    "    def __init__(self, imgs_list, class_to_int, transforms = None):\n",
    "        super().__init__()\n",
    "        self.imgs_list = imgs_list\n",
    "        self.class_to_int = class_to_int\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.imgs_list[index]\n",
    "        \n",
    "        #Reading image\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "        \n",
    "        #Retriving class label\n",
    "        label = image_path.split(\"/\")[-2]\n",
    "        # label = self.class_to_int[label]\n",
    "        \n",
    "        #Applying transforms on image\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        return image, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ABBOTTS BABBLER'"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = train_imgs[1]\n",
    "dfss = aa.split(\"/\")[-2]\n",
    "dfss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "set = Birds_dataset(train_imgs, 1, data_transforms_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Birdi_dataset(Dataset):    \n",
    "    def __init__(self,path_to_imgs,labels_file,transform=None,trarget_transform=None):\n",
    "        # labels_file contains filename and label for that file\n",
    "        # type equal to type of data set\n",
    "        self.labels = pd.read_csv(labels_file)\n",
    "        self.path_to_imgs = path_to_imgs\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        path_to_imgs = os.path.join(self.path_to_imgs,self.labels.iloc[idx,1]) ##\n",
    "        image = read_image(path_to_imgs)\n",
    "        # print(type(image))\n",
    "        label = self.labels.iloc[idx,2]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bird_dataset(Dataset):    \n",
    "    def __init__(self,path_to_imgs,labels_file,type,transform=None,trarget_transform=None):\n",
    "        # labels_file contains filename and label for that file\n",
    "        # type equal to type of data set\n",
    "        self.labels = labels_file.loc[labels_file['data set'].isin([type.format()])]\n",
    "        self.path_to_imgs = path_to_imgs\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        path_to_imgs = os.path.join(self.path_to_imgs,self.labels.iloc[idx,1]) ##\n",
    "        image = read_image(path_to_imgs)\n",
    "        label = self.labels.iloc[idx,2]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = Birdi_dataset(data_dir, mf)#, transform=data_transforms_train)\n",
    "# valid_data = Bird_dataset(data_dir, df, 'valid', transform=data_transforms_other)\n",
    "# test_data = Bird_dataset(data_dir, df, 'test', transform=data_transforms_other)\n",
    "\n",
    "#Setting the corrosponding labels with their classes\n",
    "train_image_folder = datasets.ImageFolder(data_dir + \"/train\", transform=data_transforms_train)\n",
    "valid_image_folder = datasets.ImageFolder(data_dir + \"/valid\", transform=data_transforms_other)\n",
    "test_image_folder = datasets.ImageFolder(data_dir + \"/test\", transform=data_transforms_other)\n",
    "idx_to_class = {v: k for k, v in train_image_folder.class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70626\n"
     ]
    }
   ],
   "source": [
    "sampler_train = RandomSampler(train_image_folder)\n",
    "sampler_valid = RandomSampler(valid_data)\n",
    "sampler_test = RandomSampler(test_data)\n",
    "\n",
    "print(sampler_train.num_samples)\n",
    "\n",
    "# batch_size = 20\n",
    "# #Shuffle Argument is mutually exclusive with Sampler!\n",
    "# train_data_loader = create_dataloader(train_data, batch_size, sampler_train)\n",
    "# valid_data_loader = create_dataloader(valid_data, batch_size, sampler_valid)\n",
    "# test_data_loader = create_dataloader(test_data, batch_size, sampler_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BirdModel,self).__init__()\n",
    "        # convolutional layer (3x224x224)\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3, padding=1) # add last\n",
    "        # convolutional layer (6x224x224)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, padding=0)\n",
    "        # convolutional layer (16x222x222)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3, padding=0)\n",
    "        # convolutional layer (32x220x220)\n",
    "        self.conv4 = nn.Conv2d(32, 64, 5, padding=0)\n",
    "        # output tensor size is 64x216x216\n",
    "        # max pooling layer\n",
    "        self.pool = nn.MaxPool2d(4, 4)\n",
    "        # output tensor size is 64x54x54\n",
    "        # linear layer (64 * 54 * 54 -> 1000) (+kernal)\n",
    "        self.fc1 = nn.Linear(64 * 54 * 54, 1000)\n",
    "        # linear layer (2000 -> 450)\n",
    "        self.fc2 = nn.Linear(1000, 450)\n",
    "        # dropout layer (p=0.25)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.relu(self.conv4(x)) # add last\n",
    "        x = self.pool(x)\n",
    "        # flatten image input\n",
    "        x = x.view(-1, 64 * 54 * 54)\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add 1st hidden layer, with relu activation function\n",
    "        x = self.relu(self.fc1(x))\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add 2nd hidden layer, with relu activation function\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(data_loader,model,device,loss_fn,optimizer,print_every_n=500):\n",
    "    model.train()\n",
    "    size = len(data_loader.dataset)\n",
    "    num_batches = len(data_loader)\n",
    "    train_loss=0\n",
    "    tp=0\n",
    "    for batch,(X,y) in enumerate(data_loader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(dtype=torch.long)\n",
    "        y = y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred,y)\n",
    "        train_loss += loss\n",
    "        tp += (y==pred.argmax(1)).type(torch.float).sum().item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch%print_every_n==0:\n",
    "            loss, current = loss.item(), batch*len(X)\n",
    "            print(f'loss={loss:.3f}, {current} samples / {size}')\n",
    "\n",
    "        \n",
    "        \n",
    "    train_loss /= num_batches\n",
    "    train_acc = tp/size    \n",
    "        \n",
    "    return train_loss,train_acc\n",
    "\n",
    "def valid_loop(data_loader,model,device,loss_fn):\n",
    "    model.eval()\n",
    "    size=len(data_loader.dataset)\n",
    "    num_batches = len(data_loader)\n",
    "    valid_loss=0\n",
    "    tp=0\n",
    "    with torch.no_grad():\n",
    "        for images,Labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            Labels = Labels.to(dtype=torch.long)\n",
    "            Labels = Labels.to(device)\n",
    "            pred = model(images)\n",
    "            valid_loss += loss_fn(pred,Labels).item()\n",
    "            tp += (Labels==pred.argmax(1)).type(torch.float).sum().item()\n",
    "        \n",
    "    valid_loss /= num_batches\n",
    "    valid_acc = tp/size\n",
    "    print(f'accuracy = {valid_acc}, valid_loss = {valid_loss:2f}')\n",
    "    return valid_loss,valid_acc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model,device,dataloader,loss_fn,optimizer):\n",
    "    train_loss,train_correct=0.0,0\n",
    "    model.train()\n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = loss_fn(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        scores, predictions = torch.max(output.data, 1)\n",
    "        train_correct += (predictions == labels).sum().item()\n",
    "\n",
    "    return train_loss,train_correct\n",
    "  \n",
    "def valid_epoch(model,device,dataloader,loss_fn):\n",
    "    valid_loss, val_correct = 0.0, 0\n",
    "    model.eval()\n",
    "    for images, labels in dataloader:\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        output = model(images)\n",
    "        loss=loss_fn(output,labels)\n",
    "        valid_loss+=loss.item()*images.size(0)\n",
    "        scores, predictions = torch.max(output.data,1)\n",
    "        val_correct+=(predictions == labels).sum().item()\n",
    "\n",
    "    return valid_loss,val_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement K-fold**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Divide the data into K folds in order to keep the balance of the original data set*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "K = 5 # number of folds for cross validation\n",
    "skf = StratifiedKFold(n_splits = K, shuffle=True)\n",
    "# skf = KFold(n_splits=5)\n",
    "batch_size = 20\n",
    "learning_rate = 1e-3\n",
    "epochs = 10\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = df.filepaths\n",
    "ys = df.labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(xs, ys, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "loss=6.114, 0 samples / 70626\n",
      "loss=5.900, 10000 samples / 70626\n",
      "loss=6.001, 20000 samples / 70626\n",
      "loss=5.925, 30000 samples / 70626\n",
      "loss=5.915, 40000 samples / 70626\n",
      "loss=5.955, 50000 samples / 70626\n",
      "loss=5.901, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.948339\n",
      "Epoch:1/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.991, 0 samples / 70626\n",
      "loss=5.933, 10000 samples / 70626\n",
      "loss=5.939, 20000 samples / 70626\n",
      "loss=5.960, 30000 samples / 70626\n",
      "loss=5.939, 40000 samples / 70626\n",
      "loss=5.953, 50000 samples / 70626\n",
      "loss=5.911, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.950970\n",
      "Epoch:2/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.941, 0 samples / 70626\n",
      "loss=5.939, 10000 samples / 70626\n",
      "loss=5.926, 20000 samples / 70626\n",
      "loss=5.931, 30000 samples / 70626\n",
      "loss=5.902, 40000 samples / 70626\n",
      "loss=5.949, 50000 samples / 70626\n",
      "loss=5.976, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.954598\n",
      "Epoch:3/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.903, 0 samples / 70626\n",
      "loss=5.901, 10000 samples / 70626\n",
      "loss=5.964, 20000 samples / 70626\n",
      "loss=5.909, 30000 samples / 70626\n",
      "loss=5.941, 40000 samples / 70626\n",
      "loss=5.940, 50000 samples / 70626\n",
      "loss=5.928, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.949441\n",
      "Epoch:4/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.967, 0 samples / 70626\n",
      "loss=5.948, 10000 samples / 70626\n",
      "loss=5.950, 20000 samples / 70626\n",
      "loss=5.986, 30000 samples / 70626\n",
      "loss=5.998, 40000 samples / 70626\n",
      "loss=5.970, 50000 samples / 70626\n",
      "loss=5.992, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.949832\n",
      "Epoch:5/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.935, 0 samples / 70626\n",
      "loss=5.963, 10000 samples / 70626\n",
      "loss=5.984, 20000 samples / 70626\n",
      "loss=5.883, 30000 samples / 70626\n",
      "loss=5.972, 40000 samples / 70626\n",
      "loss=5.939, 50000 samples / 70626\n",
      "loss=5.972, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.948237\n",
      "Epoch:6/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.980, 0 samples / 70626\n",
      "loss=5.993, 10000 samples / 70626\n",
      "loss=5.912, 20000 samples / 70626\n",
      "loss=5.930, 30000 samples / 70626\n",
      "loss=5.921, 40000 samples / 70626\n",
      "loss=5.931, 50000 samples / 70626\n",
      "loss=5.953, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.949727\n",
      "Epoch:7/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.994, 0 samples / 70626\n",
      "loss=5.973, 10000 samples / 70626\n",
      "loss=5.937, 20000 samples / 70626\n",
      "loss=5.935, 30000 samples / 70626\n",
      "loss=5.915, 40000 samples / 70626\n",
      "loss=5.934, 50000 samples / 70626\n",
      "loss=5.942, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.949651\n",
      "Epoch:8/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.929, 0 samples / 70626\n",
      "loss=5.909, 10000 samples / 70626\n",
      "loss=5.958, 20000 samples / 70626\n",
      "loss=5.970, 30000 samples / 70626\n",
      "loss=5.927, 40000 samples / 70626\n",
      "loss=5.952, 50000 samples / 70626\n",
      "loss=5.923, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.949323\n",
      "Epoch:9/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.938, 0 samples / 70626\n",
      "loss=5.894, 10000 samples / 70626\n",
      "loss=5.935, 20000 samples / 70626\n",
      "loss=5.932, 30000 samples / 70626\n",
      "loss=5.950, 40000 samples / 70626\n",
      "loss=5.910, 50000 samples / 70626\n",
      "loss=5.955, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.949661\n",
      "Epoch:10/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "Fold 2\n",
      "loss=6.104, 0 samples / 70626\n",
      "loss=5.101, 10000 samples / 70626\n",
      "loss=4.439, 20000 samples / 70626\n",
      "loss=5.275, 30000 samples / 70626\n",
      "loss=3.987, 40000 samples / 70626\n",
      "loss=5.152, 50000 samples / 70626\n",
      "loss=5.192, 60000 samples / 70626\n",
      "accuracy = 0.01571659162348144, valid_loss = 4.869614\n",
      "Epoch:1/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=4.964, 0 samples / 70626\n",
      "loss=4.206, 10000 samples / 70626\n",
      "loss=4.064, 20000 samples / 70626\n",
      "loss=4.897, 30000 samples / 70626\n",
      "loss=5.196, 40000 samples / 70626\n",
      "loss=4.129, 50000 samples / 70626\n",
      "loss=4.860, 60000 samples / 70626\n",
      "accuracy = 0.02064395548381616, valid_loss = 4.637775\n",
      "Epoch:2/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=4.625, 0 samples / 70626\n",
      "loss=4.412, 10000 samples / 70626\n",
      "loss=4.455, 20000 samples / 70626\n",
      "loss=4.057, 30000 samples / 70626\n",
      "loss=4.296, 40000 samples / 70626\n",
      "loss=4.148, 50000 samples / 70626\n",
      "loss=3.913, 60000 samples / 70626\n",
      "accuracy = 0.03133406960609407, valid_loss = 4.248831\n",
      "Epoch:3/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=4.144, 0 samples / 70626\n",
      "loss=4.205, 10000 samples / 70626\n",
      "loss=4.014, 20000 samples / 70626\n",
      "loss=3.780, 30000 samples / 70626\n",
      "loss=3.512, 40000 samples / 70626\n",
      "loss=3.295, 50000 samples / 70626\n",
      "loss=4.404, 60000 samples / 70626\n",
      "accuracy = 0.04427547928524906, valid_loss = 3.881166\n",
      "Epoch:4/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=4.112, 0 samples / 70626\n",
      "loss=3.822, 10000 samples / 70626\n",
      "loss=3.898, 20000 samples / 70626\n",
      "loss=3.794, 30000 samples / 70626\n",
      "loss=4.430, 40000 samples / 70626\n",
      "loss=3.339, 50000 samples / 70626\n",
      "loss=3.812, 60000 samples / 70626\n",
      "accuracy = 0.0549372752244216, valid_loss = 3.512314\n",
      "Epoch:5/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=3.329, 0 samples / 70626\n",
      "loss=3.385, 10000 samples / 70626\n",
      "loss=3.444, 20000 samples / 70626\n",
      "loss=2.779, 30000 samples / 70626\n",
      "loss=3.101, 40000 samples / 70626\n",
      "loss=3.518, 50000 samples / 70626\n",
      "loss=2.627, 60000 samples / 70626\n",
      "accuracy = 0.06137966188089372, valid_loss = 3.356193\n",
      "Epoch:6/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=2.842, 0 samples / 70626\n",
      "loss=3.595, 10000 samples / 70626\n",
      "loss=3.066, 20000 samples / 70626\n",
      "loss=3.352, 30000 samples / 70626\n",
      "loss=3.137, 40000 samples / 70626\n",
      "loss=3.335, 50000 samples / 70626\n",
      "loss=2.873, 60000 samples / 70626\n",
      "accuracy = 0.06953529861524084, valid_loss = 3.137596\n",
      "Epoch:7/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=3.171, 0 samples / 70626\n",
      "loss=3.765, 10000 samples / 70626\n",
      "loss=2.449, 20000 samples / 70626\n",
      "loss=2.958, 30000 samples / 70626\n",
      "loss=3.249, 40000 samples / 70626\n",
      "loss=2.915, 50000 samples / 70626\n",
      "loss=3.344, 60000 samples / 70626\n",
      "accuracy = 0.07467504884886586, valid_loss = 2.984306\n",
      "Epoch:8/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=2.367, 0 samples / 70626\n",
      "loss=3.273, 10000 samples / 70626\n",
      "loss=2.285, 20000 samples / 70626\n",
      "loss=3.045, 30000 samples / 70626\n",
      "loss=3.439, 40000 samples / 70626\n",
      "loss=2.882, 50000 samples / 70626\n",
      "loss=3.176, 60000 samples / 70626\n",
      "accuracy = 0.08723416305609832, valid_loss = 2.704779\n",
      "Epoch:9/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=2.517, 0 samples / 70626\n",
      "loss=2.753, 10000 samples / 70626\n",
      "loss=2.370, 20000 samples / 70626\n",
      "loss=3.597, 30000 samples / 70626\n",
      "loss=2.209, 40000 samples / 70626\n",
      "loss=2.611, 50000 samples / 70626\n",
      "loss=3.488, 60000 samples / 70626\n",
      "accuracy = 0.089683685894713, valid_loss = 2.621761\n",
      "Epoch:10/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "Fold 3\n",
      "loss=6.110, 0 samples / 70626\n",
      "loss=5.950, 10000 samples / 70626\n",
      "loss=5.994, 20000 samples / 70626\n",
      "loss=5.955, 30000 samples / 70626\n",
      "loss=5.957, 40000 samples / 70626\n",
      "loss=5.957, 50000 samples / 70626\n",
      "loss=5.977, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.951574\n",
      "Epoch:1/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.941, 0 samples / 70626\n",
      "loss=5.977, 10000 samples / 70626\n",
      "loss=5.947, 20000 samples / 70626\n",
      "loss=5.960, 30000 samples / 70626\n",
      "loss=5.933, 40000 samples / 70626\n",
      "loss=5.947, 50000 samples / 70626\n",
      "loss=5.956, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.952639\n",
      "Epoch:2/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.926, 0 samples / 70626\n",
      "loss=5.998, 10000 samples / 70626\n",
      "loss=5.934, 20000 samples / 70626\n",
      "loss=5.937, 30000 samples / 70626\n",
      "loss=5.935, 40000 samples / 70626\n",
      "loss=5.980, 50000 samples / 70626\n",
      "loss=5.910, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.951745\n",
      "Epoch:3/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.919, 0 samples / 70626\n",
      "loss=5.966, 10000 samples / 70626\n",
      "loss=5.876, 20000 samples / 70626\n",
      "loss=5.930, 30000 samples / 70626\n",
      "loss=5.963, 40000 samples / 70626\n",
      "loss=5.957, 50000 samples / 70626\n",
      "loss=5.936, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.949822\n",
      "Epoch:4/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.938, 0 samples / 70626\n",
      "loss=5.950, 10000 samples / 70626\n",
      "loss=5.950, 20000 samples / 70626\n",
      "loss=5.958, 30000 samples / 70626\n",
      "loss=5.979, 40000 samples / 70626\n",
      "loss=5.936, 50000 samples / 70626\n",
      "loss=5.946, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.948999\n",
      "Epoch:5/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.969, 0 samples / 70626\n",
      "loss=5.953, 10000 samples / 70626\n",
      "loss=5.925, 20000 samples / 70626\n",
      "loss=5.940, 30000 samples / 70626\n",
      "loss=5.934, 40000 samples / 70626\n",
      "loss=5.969, 50000 samples / 70626\n",
      "loss=5.989, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.949988\n",
      "Epoch:6/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.943, 0 samples / 70626\n",
      "loss=5.960, 10000 samples / 70626\n",
      "loss=5.940, 20000 samples / 70626\n",
      "loss=5.970, 30000 samples / 70626\n",
      "loss=5.922, 40000 samples / 70626\n",
      "loss=5.959, 50000 samples / 70626\n",
      "loss=5.921, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.950151\n",
      "Epoch:7/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.944, 0 samples / 70626\n",
      "loss=5.944, 10000 samples / 70626\n",
      "loss=5.933, 20000 samples / 70626\n",
      "loss=5.978, 30000 samples / 70626\n",
      "loss=5.977, 40000 samples / 70626\n",
      "loss=5.961, 50000 samples / 70626\n",
      "loss=5.945, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.949500\n",
      "Epoch:8/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.961, 0 samples / 70626\n",
      "loss=5.939, 10000 samples / 70626\n",
      "loss=5.976, 20000 samples / 70626\n",
      "loss=5.940, 30000 samples / 70626\n",
      "loss=5.984, 40000 samples / 70626\n",
      "loss=5.893, 50000 samples / 70626\n",
      "loss=5.948, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.951674\n",
      "Epoch:9/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.948, 0 samples / 70626\n",
      "loss=5.912, 10000 samples / 70626\n",
      "loss=6.006, 20000 samples / 70626\n",
      "loss=5.934, 30000 samples / 70626\n",
      "loss=5.895, 40000 samples / 70626\n",
      "loss=5.922, 50000 samples / 70626\n",
      "loss=5.990, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.950374\n",
      "Epoch:10/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "Fold 4\n",
      "loss=6.114, 0 samples / 70626\n",
      "loss=5.963, 10000 samples / 70626\n",
      "loss=5.986, 20000 samples / 70626\n",
      "loss=5.946, 30000 samples / 70626\n",
      "loss=5.956, 40000 samples / 70626\n",
      "loss=5.971, 50000 samples / 70626\n",
      "loss=5.920, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.948816\n",
      "Epoch:1/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.955, 0 samples / 70626\n",
      "loss=5.890, 10000 samples / 70626\n",
      "loss=5.924, 20000 samples / 70626\n",
      "loss=5.924, 30000 samples / 70626\n",
      "loss=5.967, 40000 samples / 70626\n",
      "loss=5.946, 50000 samples / 70626\n",
      "loss=5.972, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.954285\n",
      "Epoch:2/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.958, 0 samples / 70626\n",
      "loss=5.958, 10000 samples / 70626\n",
      "loss=5.996, 20000 samples / 70626\n",
      "loss=5.916, 30000 samples / 70626\n",
      "loss=5.964, 40000 samples / 70626\n",
      "loss=5.950, 50000 samples / 70626\n",
      "loss=5.927, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.950718\n",
      "Epoch:3/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.993, 0 samples / 70626\n",
      "loss=5.945, 10000 samples / 70626\n",
      "loss=5.909, 20000 samples / 70626\n",
      "loss=5.954, 30000 samples / 70626\n",
      "loss=5.945, 40000 samples / 70626\n",
      "loss=5.916, 50000 samples / 70626\n",
      "loss=5.909, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.945966\n",
      "Epoch:4/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.943, 0 samples / 70626\n",
      "loss=5.944, 10000 samples / 70626\n",
      "loss=5.917, 20000 samples / 70626\n",
      "loss=5.926, 30000 samples / 70626\n",
      "loss=5.968, 40000 samples / 70626\n",
      "loss=5.961, 50000 samples / 70626\n",
      "loss=5.965, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.947694\n",
      "Epoch:5/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.977, 0 samples / 70626\n",
      "loss=5.958, 10000 samples / 70626\n",
      "loss=5.920, 20000 samples / 70626\n",
      "loss=5.958, 30000 samples / 70626\n",
      "loss=5.912, 40000 samples / 70626\n",
      "loss=5.954, 50000 samples / 70626\n",
      "loss=5.964, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.948338\n",
      "Epoch:6/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.932, 0 samples / 70626\n",
      "loss=5.957, 10000 samples / 70626\n",
      "loss=5.942, 20000 samples / 70626\n",
      "loss=5.937, 30000 samples / 70626\n",
      "loss=5.948, 40000 samples / 70626\n",
      "loss=5.927, 50000 samples / 70626\n",
      "loss=5.948, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.948257\n",
      "Epoch:7/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.884, 0 samples / 70626\n",
      "loss=5.952, 10000 samples / 70626\n",
      "loss=5.916, 20000 samples / 70626\n",
      "loss=5.970, 30000 samples / 70626\n",
      "loss=5.928, 40000 samples / 70626\n",
      "loss=5.971, 50000 samples / 70626\n",
      "loss=5.910, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.949738\n",
      "Epoch:8/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.919, 0 samples / 70626\n",
      "loss=5.941, 10000 samples / 70626\n",
      "loss=5.951, 20000 samples / 70626\n",
      "loss=5.997, 30000 samples / 70626\n",
      "loss=5.951, 40000 samples / 70626\n",
      "loss=5.968, 50000 samples / 70626\n",
      "loss=5.961, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.949461\n",
      "Epoch:9/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.924, 0 samples / 70626\n",
      "loss=5.949, 10000 samples / 70626\n",
      "loss=5.996, 20000 samples / 70626\n",
      "loss=5.908, 30000 samples / 70626\n",
      "loss=5.907, 40000 samples / 70626\n",
      "loss=5.923, 50000 samples / 70626\n",
      "loss=5.940, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.949425\n",
      "Epoch:10/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "Fold 5\n",
      "loss=6.112, 0 samples / 70626\n",
      "loss=5.898, 10000 samples / 70626\n",
      "loss=5.941, 20000 samples / 70626\n",
      "loss=5.996, 30000 samples / 70626\n",
      "loss=5.954, 40000 samples / 70626\n",
      "loss=5.922, 50000 samples / 70626\n",
      "loss=5.947, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.955117\n",
      "Epoch:1/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.942, 0 samples / 70626\n",
      "loss=5.931, 10000 samples / 70626\n",
      "loss=5.942, 20000 samples / 70626\n",
      "loss=5.946, 30000 samples / 70626\n",
      "loss=5.993, 40000 samples / 70626\n",
      "loss=5.965, 50000 samples / 70626\n",
      "loss=5.960, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.948510\n",
      "Epoch:2/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.975, 0 samples / 70626\n",
      "loss=5.940, 10000 samples / 70626\n",
      "loss=5.981, 20000 samples / 70626\n",
      "loss=5.960, 30000 samples / 70626\n",
      "loss=5.921, 40000 samples / 70626\n",
      "loss=5.943, 50000 samples / 70626\n",
      "loss=5.947, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.951266\n",
      "Epoch:3/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.992, 0 samples / 70626\n",
      "loss=6.003, 10000 samples / 70626\n",
      "loss=5.975, 20000 samples / 70626\n",
      "loss=5.959, 30000 samples / 70626\n",
      "loss=5.965, 40000 samples / 70626\n",
      "loss=5.960, 50000 samples / 70626\n",
      "loss=5.938, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.950124\n",
      "Epoch:4/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.954, 0 samples / 70626\n",
      "loss=5.945, 10000 samples / 70626\n",
      "loss=5.949, 20000 samples / 70626\n",
      "loss=5.964, 30000 samples / 70626\n",
      "loss=5.952, 40000 samples / 70626\n",
      "loss=6.002, 50000 samples / 70626\n",
      "loss=5.976, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.951126\n",
      "Epoch:5/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.951, 0 samples / 70626\n",
      "loss=5.936, 10000 samples / 70626\n",
      "loss=5.929, 20000 samples / 70626\n",
      "loss=5.920, 30000 samples / 70626\n",
      "loss=5.929, 40000 samples / 70626\n",
      "loss=5.925, 50000 samples / 70626\n",
      "loss=5.936, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.948892\n",
      "Epoch:6/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.947, 0 samples / 70626\n",
      "loss=5.960, 10000 samples / 70626\n",
      "loss=5.920, 20000 samples / 70626\n",
      "loss=5.932, 30000 samples / 70626\n",
      "loss=5.958, 40000 samples / 70626\n",
      "loss=5.965, 50000 samples / 70626\n",
      "loss=5.974, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.949629\n",
      "Epoch:7/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.949, 0 samples / 70626\n",
      "loss=5.955, 10000 samples / 70626\n",
      "loss=5.951, 20000 samples / 70626\n",
      "loss=5.948, 30000 samples / 70626\n",
      "loss=5.949, 40000 samples / 70626\n",
      "loss=5.986, 50000 samples / 70626\n",
      "loss=5.968, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.950203\n",
      "Epoch:8/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.935, 0 samples / 70626\n",
      "loss=5.925, 10000 samples / 70626\n",
      "loss=5.945, 20000 samples / 70626\n",
      "loss=5.946, 30000 samples / 70626\n",
      "loss=5.945, 40000 samples / 70626\n",
      "loss=5.940, 50000 samples / 70626\n",
      "loss=5.937, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.949415\n",
      "Epoch:9/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n",
      "loss=5.950, 0 samples / 70626\n",
      "loss=5.975, 10000 samples / 70626\n",
      "loss=5.953, 20000 samples / 70626\n",
      "loss=5.963, 30000 samples / 70626\n",
      "loss=5.979, 40000 samples / 70626\n",
      "loss=5.996, 50000 samples / 70626\n",
      "loss=5.948, 60000 samples / 70626\n",
      "accuracy = 0.0, valid_loss = 5.949745\n",
      "Epoch:10/10 AVG Training Loss:0.000 AVG Valid Loss:0.000 AVG Training Acc 0.00 % AVG Valid Acc 0.00 %\n"
     ]
    }
   ],
   "source": [
    "history = {'train_loss': [], 'valid_loss': [],'train_acc':[],'valid_acc':[]}\n",
    "\n",
    "for fold, (train_idx,val_idx) in enumerate(skf.split(xs,ys)):\n",
    "\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "\n",
    "    sampler_train = RandomSampler(train_idx)\n",
    "    sampler_valid = RandomSampler(val_idx)\n",
    "    train_loader = create_dataloader(train_image_folder, batch_size, sampler_train)\n",
    "    valid_loader = create_dataloader(train_image_folder, batch_size, sampler_valid)\n",
    "    \n",
    "    model = BirdModel().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_correct = train_loop(train_loader,model,device,loss_fn,optimizer)\n",
    "        valid_loss, valid_correct = valid_loop(valid_loader,model,device,loss_fn)\n",
    "\n",
    "        # train_loss, train_correct = train_epoch(model,device,train_loader,loss_fn,optimizer)\n",
    "        # valid_loss, valid_correct = valid_epoch(model,device,valid_loader,loss_fn)\n",
    "\n",
    "        train_loss = train_loss / len(train_loader.sampler)\n",
    "        train_acc = train_correct / len(train_loader.sampler) * 100\n",
    "        valid_loss = valid_loss / len(valid_loader.sampler)\n",
    "        valid_acc = valid_correct / len(valid_loader.sampler) * 100\n",
    "\n",
    "        print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Valid Loss:{:.3f} AVG Training Acc {:.2f} % AVG Valid Acc {:.2f} %\".format(epoch + 1,\n",
    "                                                                                                             epochs,\n",
    "                                                                                                             train_loss,\n",
    "                                                                                                             valid_loss,\n",
    "                                                                                                             train_acc,\n",
    "                                                                                                             valid_acc))\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['valid_loss'].append(valid_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['valid_acc'].append(valid_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate the average performances**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m avg_train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m avg_valid_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m avg_train_acc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3474\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3471\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3472\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 3474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3475\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/numpy/core/_methods.py:163\u001b[0m, in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_mean\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 163\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     rcount \u001b[38;5;241m=\u001b[39m _count_reduce_items(arr, axis, keepdims\u001b[38;5;241m=\u001b[39mkeepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/_tensor.py:955\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    953\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "avg_train_loss = np.mean(history['train_loss'])\n",
    "avg_valid_loss = np.mean(history['valid_loss'])\n",
    "avg_train_acc = np.mean(history['train_acc'])\n",
    "avg_valid_acc = np.mean(history['valid_acc'])\n",
    "\n",
    "print('Performance of {} fold cross validation'.format(K))\n",
    "print(\"Average Training Loss: {:.4f} \\t Average Valid Loss: {:.4f} \\t Average Training Acc: {:.3f} \\t Average Valid Acc: {:.3f}\".format(avg_train_loss,avg_valid_loss,avg_train_acc,avg_valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loss': [tensor(9.9345e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.9035e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.9003e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.8982e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.8971e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.8962e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.8955e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.8951e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.8949e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.8949e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(8.7047e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(7.7940e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(7.2999e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(6.7657e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(6.2581e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(5.8594e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(5.5350e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(5.2496e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(4.9810e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(4.7639e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.9344e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.9034e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.9002e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.8981e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.8967e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.8959e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.8953e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.8949e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.8947e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.8949e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.9335e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.9037e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.9004e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.8980e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.8967e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.8958e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.8952e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.8950e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.8948e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.8947e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.9344e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.9036e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.9003e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.8979e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.8967e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.8959e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.8954e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.8949e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.8948e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.8947e-05, device='cuda:0', grad_fn=<DivBackward0>)],\n",
       " 'valid_loss': [0.00039586974330339645,\n",
       "  0.00039604488789361233,\n",
       "  0.00039628631332449296,\n",
       "  0.0003959430855383707,\n",
       "  0.0003959691323449595,\n",
       "  0.0003958629542656386,\n",
       "  0.00039596215307117203,\n",
       "  0.00039595706100800605,\n",
       "  0.00039593526978308827,\n",
       "  0.0003959577653623917,\n",
       "  0.00032410075285795384,\n",
       "  0.00030867051889602075,\n",
       "  0.0002827841009921334,\n",
       "  0.0002583138470979405,\n",
       "  0.00023376465814406585,\n",
       "  0.00022337392677850425,\n",
       "  0.00020882504116848647,\n",
       "  0.00019862267703433015,\n",
       "  0.00018001855696332675,\n",
       "  0.00017449321410514766,\n",
       "  0.00039611141331475123,\n",
       "  0.0003961823025175832,\n",
       "  0.00039612280878087344,\n",
       "  0.000395994790613991,\n",
       "  0.0003959400029158294,\n",
       "  0.000396005880745313,\n",
       "  0.00039601673192630495,\n",
       "  0.0003959733689827729,\n",
       "  0.00039611809645415867,\n",
       "  0.00039603155072939755,\n",
       "  0.00039592787397094766,\n",
       "  0.0003962918560530319,\n",
       "  0.00039605443623735533,\n",
       "  0.0003957381576640452,\n",
       "  0.00039585315523246506,\n",
       "  0.0003958960376587843,\n",
       "  0.00039589064832020176,\n",
       "  0.0003959892451263054,\n",
       "  0.00039597079378864673,\n",
       "  0.00039596839213103713,\n",
       "  0.0003963472032714119,\n",
       "  0.00039590750064884294,\n",
       "  0.0003960909100934738,\n",
       "  0.00039601492907940426,\n",
       "  0.00039608162053011964,\n",
       "  0.00039593293231563424,\n",
       "  0.0003959819966427401,\n",
       "  0.00039602016577168806,\n",
       "  0.0003959676948619884,\n",
       "  0.0003959896511561757],\n",
       " 'train_acc': [4.947436316246349e-06,\n",
       "  5.795568256174294e-06,\n",
       "  5.183028521781889e-06,\n",
       "  5.583535271192308e-06,\n",
       "  5.559976050638754e-06,\n",
       "  5.8426866972814025e-06,\n",
       "  5.8426866972814025e-06,\n",
       "  5.724890594513632e-06,\n",
       "  5.8426866972814025e-06,\n",
       "  5.8426866972814025e-06,\n",
       "  5.946248328476967e-05,\n",
       "  0.0001328011165912229,\n",
       "  0.00018432427465136204,\n",
       "  0.000245270964135395,\n",
       "  0.00030996350736042566,\n",
       "  0.0003664575782466688,\n",
       "  0.0004092168520825868,\n",
       "  0.0004485836546059029,\n",
       "  0.0004944526938117059,\n",
       "  0.0005225112586263495,\n",
       "  4.85311868330529e-06,\n",
       "  5.748354168575197e-06,\n",
       "  5.5834423686570555e-06,\n",
       "  5.748354168575197e-06,\n",
       "  5.8190306542544005e-06,\n",
       "  5.8425894828141345e-06,\n",
       "  5.701236511455728e-06,\n",
       "  5.724795340015462e-06,\n",
       "  5.8425894828141345e-06,\n",
       "  5.8425894828141345e-06,\n",
       "  4.829559854745555e-06,\n",
       "  5.300736425940243e-06,\n",
       "  5.418530568738915e-06,\n",
       "  5.654118854336259e-06,\n",
       "  5.8425894828141345e-06,\n",
       "  5.889707139933603e-06,\n",
       "  5.8425894828141345e-06,\n",
       "  5.677677682895994e-06,\n",
       "  5.8425894828141345e-06,\n",
       "  5.8425894828141345e-06,\n",
       "  5.5598835400973215e-06,\n",
       "  5.135824626022103e-06,\n",
       "  5.418530568738915e-06,\n",
       "  5.442089397298649e-06,\n",
       "  5.654118854336259e-06,\n",
       "  5.8661483113738685e-06,\n",
       "  5.795471825694666e-06,\n",
       "  5.654118854336259e-06,\n",
       "  5.8425894828141345e-06,\n",
       "  5.8425894828141345e-06],\n",
       " 'valid_acc': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.00010460293925777996,\n",
       "  0.00013739737426832717,\n",
       "  0.00020854622034006037,\n",
       "  0.000294678730683854,\n",
       "  0.00036563910299115875,\n",
       "  0.0004085168843986271,\n",
       "  0.0004627973285540155,\n",
       "  0.0004970053167977761,\n",
       "  0.0005805934313217858,\n",
       "  0.0005968964119448452,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Need to send tensor to cpu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(history, torch.Tensor):\n",
    "    history = history.cpu().numpy()\n",
    "\n",
    "for i, o in enumerate(history):\n",
    "    if o is not None:\n",
    "        # sometimes output can be a list of tensor, so here ensure the type again, this fixes the error.\n",
    "        if isinstance(o, torch.Tensor):\n",
    "            o = o.cpu().numpy()\n",
    "        if i == 1:\n",
    "            train_loss = []\n",
    "            for loss in history[o]:\n",
    "                train_loss.append(loss)\n",
    "        if i == 2:\n",
    "            valid_loss = []\n",
    "            for loss in history[o]:\n",
    "                valid_loss.append(loss)\n",
    "        if i == 3:\n",
    "            train_acc = []\n",
    "            for acc in history[o]:\n",
    "                train_acc.append(acc)\n",
    "        if i == 4:\n",
    "            valid_acc = []\n",
    "            for acc in history[o]:\n",
    "                valid_acc.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of 5 fold cross validation\n",
      "Average Training Loss: 0.0004 \t Average Valid Loss: 0.0001 \t Average Training Acc: 0.000 \t Average Valid Acc: 0.000\n"
     ]
    }
   ],
   "source": [
    "avg_train_loss = np.mean(train_loss)\n",
    "avg_valid_loss = np.mean(valid_loss)\n",
    "avg_train_acc = np.mean(train_acc)\n",
    "avg_valid_acc = np.mean(valid_acc)\n",
    "\n",
    "print('Performance of {} fold cross validation'.format(K))\n",
    "print(\"Average Training Loss: {:.4f} \\t Average Valid Loss: {:.4f} \\t Average Training Acc: {:.3f} \\t Average Valid Acc: {:.3f}\".format(avg_train_loss,avg_valid_loss,avg_train_acc,avg_valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots_history(train_loss, valid_loss, train_acc, valid_acc):\n",
    "    fig, ax = plt.subplots(1,2,figsize=(12,4))\n",
    "    ax[0].plot(train_acc)\n",
    "    ax[0].plot(valid_acc)\n",
    "    ax[0].set_title('Model accuracy')\n",
    "    ax[0].set_ylabel('Accuracy')\n",
    "    ax[0].set_xlabel('10-Epochs for 1-Fold')\n",
    "    ax[0].legend(['Train', 'Valid'], loc='upper left')\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    ax[1].plot(train_loss)\n",
    "    ax[1].plot(valid_loss)\n",
    "    ax[1].set_title('Model loss')\n",
    "    ax[1].set_ylabel('Loss')\n",
    "    ax[1].set_xlabel('10-Epochs for 1-Fold')\n",
    "    ax[1].legend(['Train', 'Valid'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots_history(train_loss, valid_loss, train_acc, valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "for i in range(epochs):\n",
    "    print(f'epoch: {i+1}')\n",
    "    train_loss,train_acc = train_loop(train_data_loader,model,device,loss_fn,optimizer)\n",
    "    val_loss,val_acc = valid_loop(valid_data_loader,model,device,loss_fn)\n",
    "    history.append({'train_loss':train_loss.detach().cpu().numpy(),'val_loss':val_loss,'train_acc':train_acc,'val_acc':val_acc})\n",
    "    print('---------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.DataFrame(history)\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformation**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "1ebf76abeff0e283d6460ea42611a8884d5cda29df554b71c553aadbc210cf7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
